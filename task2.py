import matplotlib
# å¼ºåˆ¶ä½¿ç”¨Aggåç«¯ï¼ˆé€‚é…æ— GUIç¯å¢ƒï¼Œå¦‚æœåŠ¡å™¨/CIï¼‰
matplotlib.use('Agg', force=True)
import matplotlib.pyplot as plt
import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.exceptions import NotFittedError
from typing import Tuple, Dict

# ====================== å…¨å±€å‚æ•°é…ç½®åŒºï¼ˆä¸€é”®è°ƒæ•´ï¼‰ ======================
# åŸºç¡€é…ç½®
SEED = 42  # éšæœºç§å­
TEST_SIZE = 0.3  # æµ‹è¯•é›†æ¯”ä¾‹
LR_MAX_ITER = 500  # é€»è¾‘å›å½’æœ€å¤§è¿­ä»£æ•°

# å¯è§†åŒ–é…ç½®
FIG_SIZE = (12, 10)  # ç”»å¸ƒå°ºå¯¸
FIG_DPI = 300  # å›¾ç‰‡åˆ†è¾¨ç‡
VIEW_ELEV = 20  # 3Dè§†è§’ä»°è§’ï¼ˆPPTé»˜è®¤20Â°ï¼‰
VIEW_AZIM = 45  # 3Dè§†è§’æ–¹ä½è§’ï¼ˆPPTé»˜è®¤45Â°ï¼‰
CLASS_COLORS = {0: '#FF4444', 1: '#0066CC'}  # ç±»åˆ«é¢œè‰²ï¼ˆçº¢/è“ï¼Œç²¾å‡†åŒ¹é…PPTï¼‰
BOUNDARY_COLOR = '#ADD8E6'  # å†³ç­–è¶…å¹³é¢é¢œè‰²ï¼ˆlightblueåå…­è¿›åˆ¶ï¼‰
SAVE_PATH = "task2_3d_boundary.png"  # ä¿å­˜è·¯å¾„

# ç‰¹å¾é…ç½®
FEATURE_INDICES = [0, 1, 2]  # é€‰æ‹©çš„3ä¸ªç‰¹å¾ç´¢å¼•ï¼ˆè¼ç‰‡é•¿ã€è¼ç‰‡å®½ã€èŠ±ç“£é•¿ï¼‰
FEATURE_NAMES = ['Sepal Length', 'Sepal Width', 'Petal Length']  # ç‰¹å¾å

def load_and_preprocess_iris() -> Tuple[np.ndarray, np.ndarray, list]:
    """
    åŠ è½½é¸¢å°¾èŠ±æ•°æ®é›†å¹¶é¢„å¤„ç†ä¸ºäºŒåˆ†ç±»æ•°æ®
    è¿”å›ï¼š3ç»´ç‰¹å¾çŸ©é˜µï¼ˆæ ‡å‡†åŒ–ï¼‰ã€äºŒåˆ†ç±»æ ‡ç­¾ã€ç‰¹å¾å
    """
    # åŠ è½½åŸå§‹æ•°æ®
    iris = load_iris()
    X = iris.data[:, FEATURE_INDICES]  # å–æŒ‡å®š3ä¸ªç‰¹å¾
    y = iris.target
    
    # è½¬æ¢ä¸ºäºŒåˆ†ç±»ï¼ˆ0ç±»=Setosaï¼Œ1ç±»=Versicolor+Virginicaï¼‰
    y_bin = np.where(y == 0, 0, 1)
    print(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆï¼š")
    print(f"  - æ ·æœ¬æ•°ï¼š{X.shape[0]}, ç‰¹å¾æ•°ï¼š{X.shape[1]}")
    print(f"  - äºŒåˆ†ç±»æ ·æœ¬åˆ†å¸ƒï¼šClass 0(Setosa)={np.sum(y_bin==0)}, Class 1(Others)={np.sum(y_bin==1)}")
    
    # æ•°æ®ç»´åº¦æ ¡éªŒ
    if X.shape[1] != 3:
        raise ValueError(f"âŒ ç‰¹å¾ç»´åº¦é”™è¯¯ï¼šæœŸæœ›3ç»´ï¼Œå®é™…{X.shape[1]}ç»´")
    
    # æ ‡å‡†åŒ–ï¼ˆæ¶ˆé™¤é‡çº²å½±å“ï¼Œæå‡æ¨¡å‹æ•ˆæœï¼‰
    scaler = StandardScaler()
    X_scaled_3d = scaler.fit_transform(X)
    
    # æ ‡å‡†åŒ–åèŒƒå›´æ ¡éªŒ
    print(f"  - æ ‡å‡†åŒ–åç‰¹å¾èŒƒå›´ï¼š")
    for i, name in enumerate(FEATURE_NAMES):
        print(f"    {name}: [{X_scaled_3d[:, i].min():.3f}, {X_scaled_3d[:, i].max():.3f}]")
    
    return X_scaled_3d, y_bin, FEATURE_NAMES

def train_logistic_regression(X: np.ndarray, y: np.ndarray) -> Tuple[LogisticRegression, float]:
    """
    è®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹å¹¶è¯„ä¼°æµ‹è¯•é›†å‡†ç¡®ç‡
    è¿”å›ï¼šè®­ç»ƒå¥½çš„åˆ†ç±»å™¨ã€æµ‹è¯•é›†å‡†ç¡®ç‡
    """
    # åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†ï¼ˆåˆ†å±‚æŠ½æ ·ï¼Œä¿è¯ç±»åˆ«åˆ†å¸ƒï¼‰
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=TEST_SIZE, random_state=SEED, stratify=y
    )
    
    try:
        # è®­ç»ƒæ¨¡å‹ï¼ˆæ˜¾å¼æŒ‡å®šæ±‚è§£å™¨ï¼Œé¿å…ç‰ˆæœ¬å…¼å®¹è­¦å‘Šï¼‰
        clf = LogisticRegression(
            max_iter=LR_MAX_ITER,
            random_state=SEED,
            solver='lbfgs'
        )
        clf.fit(X_train, y_train)
        
        # è¯„ä¼°å‡†ç¡®ç‡
        test_acc = clf.score(X_test, y_test)
        print(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼š")
        print(f"  - è¿­ä»£æ•°ï¼š{clf.n_iter_[0]}/{LR_MAX_ITER}")
        print(f"  - æµ‹è¯•é›†å‡†ç¡®ç‡ï¼š{test_acc:.3f}")
        
        return clf, test_acc
    except Exception as e:
        raise RuntimeError(f"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥ï¼š{str(e)}")

def calculate_3d_decision_plane(clf: LogisticRegression, X: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    è®¡ç®—3Då†³ç­–è¶…å¹³é¢ï¼ˆæ–¹ç¨‹ï¼šw1x1 + w2x2 + w3x3 + b = 0ï¼‰
    è¿”å›ï¼šx1, x2ï¼ˆç½‘æ ¼ï¼‰ã€x3ï¼ˆè¶…å¹³é¢ä¸Šçš„zå€¼ï¼‰
    """
    # è·å–æ¨¡å‹æƒé‡å’Œåç½®
    coef_weights = clf.coef_[0]  # æƒé‡å‘é‡ [w1, w2, w3]
    intercept_bias = clf.intercept_[0]  # åç½®é¡¹ b
    
    # æ‰“å°è¶…å¹³é¢æ–¹ç¨‹ï¼ˆä¾¿äºéªŒè¯ï¼‰
    print(f"âœ… å†³ç­–è¶…å¹³é¢æ–¹ç¨‹ï¼š")
    print(f"  {coef_weights[0]:.3f}*x1 + {coef_weights[1]:.3f}*x2 + {coef_weights[2]:.3f}*x3 + {intercept_bias:.3f} = 0")
    
    # æ ¡éªŒæƒé‡éé›¶ï¼ˆé¿å…é™¤ä»¥é›¶ï¼‰
    if abs(coef_weights[2]) < 1e-8:
        raise ValueError(f"âŒ ç¬¬3ä¸ªç‰¹å¾æƒé‡æ¥è¿‘0ï¼ˆ{coef_weights[2]:.8f}ï¼‰ï¼Œæ— æ³•æ±‚è§£x3")
    
    # ç”Ÿæˆx1-x2ç½‘æ ¼
    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    x1, x2 = np.meshgrid(
        np.linspace(x1_min, x1_max, 20),
        np.linspace(x2_min, x2_max, 20)
    )
    
    # æ±‚è§£è¶…å¹³é¢ä¸Šçš„x3å€¼ï¼ˆx3 = -(w1x1 + w2x2 + b)/w3ï¼‰
    x3 = -(coef_weights[0] * x1 + coef_weights[1] * x2 + intercept_bias) / coef_weights[2]
    
    print(f"âœ… 3Då†³ç­–è¶…å¹³é¢è®¡ç®—å®Œæˆï¼š")
    print(f"  - ç½‘æ ¼èŒƒå›´ï¼šx1[{x1_min:.3f}, {x1_max:.3f}], x2[{x2_min:.3f}, {x2_max:.3f}]")
    
    return x1, x2, x3

def plot_3d_decision_boundary(X: np.ndarray, y: np.ndarray, x1: np.ndarray, x2: np.ndarray, 
                              x3: np.ndarray, test_acc: float, feature_names: list):
    """
    ç»˜åˆ¶3Då†³ç­–è¾¹ç•Œå›¾ï¼ˆåŒ¹é…PPTæ ·å¼ï¼‰ï¼Œå¹¶ä¿å­˜å›¾ç‰‡
    """
    # åˆ›å»ºç”»å¸ƒå’Œ3Dè½´
    fig = plt.figure(figsize=FIG_SIZE, dpi=FIG_DPI)
    ax = fig.add_subplot(111, projection='3d')
    
    # 1. ç»˜åˆ¶å†³ç­–è¶…å¹³é¢ï¼ˆåŠé€æ˜æµ…è“è‰²ï¼ŒPPTåŒæ¬¾æ•ˆæœï¼‰
    ax.plot_surface(
        x1, x2, x3,
        color=BOUNDARY_COLOR,
        alpha=0.5,
        edgecolor='none',
        shade=False
    )
    
    # 2. ç»˜åˆ¶åŸå§‹æ•°æ®ç‚¹ï¼ˆåŒºåˆ†ä¸¤ç±»ï¼‰
    mask_0 = y == 0  # Class 0 (Setosa)
    mask_1 = y == 1  # Class 1 (Others)
    
    # Class 0 æ•°æ®ç‚¹ï¼ˆçº¢è‰²ï¼‰
    ax.scatter(
        X[mask_0, 0], X[mask_0, 1], X[mask_0, 2],
        c=CLASS_COLORS[0], s=80, edgecolors='black', linewidth=1,
        label='Setosa (Class 0)', zorder=5, alpha=0.9
    )
    
    # Class 1 æ•°æ®ç‚¹ï¼ˆè“è‰²ï¼‰
    ax.scatter(
        X[mask_1, 0], X[mask_1, 1], X[mask_1, 2],
        c=CLASS_COLORS[1], s=80, edgecolors='black', linewidth=1,
        label='Others (Class 1)', zorder=5, alpha=0.9
    )
    
    # 3. æ ·å¼è°ƒæ•´ï¼ˆç²¾å‡†åŒ¹é…PPTï¼‰
    ax.view_init(elev=VIEW_ELEV, azim=VIEW_AZIM)  # PPTé»˜è®¤è§†è§’
    ax.set_xlabel(feature_names[0], fontsize=12, labelpad=10)
    ax.set_ylabel(feature_names[1], fontsize=12, labelpad=10)
    ax.set_zlabel(feature_names[2], fontsize=12, labelpad=10)
    ax.set_title(
        f'Task 2: 3D Decision Boundary (Test Acc: {test_acc:.3f})',
        fontsize=16, pad=20
    )
    ax.legend(loc='upper right', fontsize=11, framealpha=0.9)
    ax.grid(alpha=0.3)  # ç½‘æ ¼åŠé€æ˜ï¼Œä¸é®æŒ¡å†…å®¹
    
    # 4. ä¿å­˜å›¾ç‰‡ï¼ˆtightå¸ƒå±€é¿å…è£å‰ªï¼‰
    plt.tight_layout()
    plt.savefig(SAVE_PATH, dpi=FIG_DPI, bbox_inches='tight')
    print(f"âœ… å¯è§†åŒ–å›¾ç‰‡å·²ä¿å­˜è‡³ï¼š{SAVE_PATH}")
    
    # é‡Šæ”¾ç”»å¸ƒèµ„æº
    plt.close(fig)

def main():
    """ä¸»å‡½æ•°ï¼šä¸²è”æ‰€æœ‰æµç¨‹"""
    try:
        print("="*60)
        print("ğŸš€ å¼€å§‹æ‰§è¡ŒTask 2ï¼š3Då†³ç­–è¾¹ç•Œç»˜åˆ¶")
        print("="*60)
        
        # 1. åŠ è½½å¹¶é¢„å¤„ç†æ•°æ®
        X_scaled_3d, y_bin, feature_names = load_and_preprocess_iris()
        
        # 2. è®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹
        clf, test_acc = train_logistic_regression(X_scaled_3d, y_bin)
        
        # 3. è®¡ç®—3Då†³ç­–è¶…å¹³é¢
        x1, x2, x3 = calculate_3d_decision_plane(clf, X_scaled_3d)
        
        # 4. ç»˜åˆ¶å¹¶ä¿å­˜3Då†³ç­–è¾¹ç•Œå›¾
        plot_3d_decision_boundary(X_scaled_3d, y_bin, x1, x2, x3, test_acc, feature_names)
        
        print("\nğŸ‰ ä»»åŠ¡äºŒå®Œæˆï¼")
        print(f"ğŸ“‹ äºŒåˆ†ç±»å‡†ç¡®ç‡ï¼š{test_acc:.3f}ï¼ˆSetosaä¸å…¶ä»–ä¸¤ç±»çº¿æ€§å¯åˆ†ï¼‰")
        print("="*60)
        
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå¤±è´¥ï¼š{str(e)}")
        raise  # æŠ›å‡ºå¼‚å¸¸ä¾¿äºè°ƒè¯•

if __name__ == "__main__":
    main()