import matplotlib
# å¼ºåˆ¶ä½¿ç”¨æ— ç•Œé¢åç«¯ï¼ˆé€‚é…æœåŠ¡å™¨/æ— GUIç¯å¢ƒï¼‰
matplotlib.use('Agg', force=True)
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.exceptions import NotFittedError
from typing import Tuple, Dict

# ====================== å…¨å±€å‚æ•°é…ç½®åŒºï¼ˆä¸€é”®è°ƒæ•´ï¼‰ ======================
# åŸºç¡€é…ç½®
SEED = 42  # éšæœºç§å­
TEST_SIZE = 0.3  # æµ‹è¯•é›†æ¯”ä¾‹
LR_MAX_ITER = 200  # é€»è¾‘å›å½’æœ€å¤§è¿­ä»£æ•°
GRID_STEP = 0.1  # ç½‘æ ¼æ­¥é•¿ï¼ˆè¶Šå°è¶Šç²¾ç»†ï¼Œé€Ÿåº¦è¶Šæ…¢ï¼‰

# å¯è§†åŒ–é…ç½®
FIG_SIZE = (20, 5)  # ç”»å¸ƒå°ºå¯¸ï¼ˆ1è¡Œ4åˆ—ï¼‰
FIG_DPI = 300  # å›¾ç‰‡åˆ†è¾¨ç‡
CLASS_COLORS = ['yellow', 'green', 'blue']  # ä¸‰ç±»é¸¢å°¾èŠ±é…è‰²ï¼ˆé»„/ç»¿/è“ï¼‰
SAVE_PATH = "iris_classifier_result.png"  # ä¿å­˜è·¯å¾„
TITLE_FONT_SIZE = 14  # å­å›¾æ ‡é¢˜å­—ä½“å¤§å°
LABEL_FONT_SIZE = 12  # åæ ‡è½´æ ‡ç­¾å­—ä½“å¤§å°

# ç‰¹å¾é…ç½®
FEATURE_IDX = [2, 3]  # é€‰æ‹©åä¸¤ä¸ªç‰¹å¾ï¼ˆPetal Length, Petal Widthï¼‰
FEATURE_NAMES = ['Petal Length', 'Petal Width']  # ç‰¹å¾åï¼ˆä¿®å¤åŸä»£ç Sepal Widthé”™è¯¯ï¼‰

def load_iris_data() -> Tuple[np.ndarray, np.ndarray, list]:
    """
    åŠ è½½é¸¢å°¾èŠ±æ•°æ®é›†ï¼Œé€‰æ‹©æŒ‡å®šç‰¹å¾
    è¿”å›ï¼šç‰¹å¾çŸ©é˜µï¼ˆåä¸¤ä¸ªç‰¹å¾ï¼‰ã€æ ‡ç­¾ã€ç±»åˆ«åç§°
    """
    iris = load_iris()
    X = iris.data[:, FEATURE_IDX]  # é€‰æ‹©åä¸¤ä¸ªç‰¹å¾
    y = iris.target
    target_names = iris.target_names
    
    # æ•°æ®æ ¡éªŒ
    if X.shape[1] != 2:
        raise ValueError(f"âŒ ç‰¹å¾ç»´åº¦é”™è¯¯ï¼šæœŸæœ›2ç»´ï¼Œå®é™…{X.shape[1]}ç»´")
    
    print(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆï¼š")
    print(f"  - æ ·æœ¬æ•°ï¼š{X.shape[0]}, ç‰¹å¾æ•°ï¼š{X.shape[1]}")
    print(f"  - ç±»åˆ«æ•°ï¼š{len(np.unique(y))}ï¼ˆ{target_names.tolist()}ï¼‰")
    print(f"  - ç‰¹å¾èŒƒå›´ï¼š")
    for i, name in enumerate(FEATURE_NAMES):
        print(f"    {name}: [{X[:, i].min():.2f}, {X[:, i].max():.2f}]")
    
    return X, y, target_names

def train_logistic_regression(X: np.ndarray, y: np.ndarray) -> Tuple[LogisticRegression, float]:
    """
    è®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹ï¼Œè¯„ä¼°æµ‹è¯•é›†å‡†ç¡®ç‡
    è¿”å›ï¼šè®­ç»ƒå¥½çš„æ¨¡å‹ã€æµ‹è¯•é›†å‡†ç¡®ç‡
    """
    # åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†ï¼ˆåˆ†å±‚æŠ½æ ·ï¼‰
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=TEST_SIZE, random_state=SEED, stratify=y
    )
    
    try:
        # è®­ç»ƒæ¨¡å‹
        model = LogisticRegression(max_iter=LR_MAX_ITER, random_state=SEED)
        model.fit(X_train, y_train)
        
        # è¯„ä¼°å‡†ç¡®ç‡
        test_acc = model.score(X_test, y_test)
        print(f"\nâœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼š")
        print(f"  - è¿­ä»£æ•°ï¼š{model.n_iter_[0]}/{LR_MAX_ITER}")
        print(f"  - æµ‹è¯•é›†å‡†ç¡®ç‡ï¼š{test_acc:.3f}")
        
        return model, test_acc
    except Exception as e:
        raise RuntimeError(f"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥ï¼š{str(e)}")

def generate_grid(X: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    ç”Ÿæˆ2Dç½‘æ ¼ç”¨äºå†³ç­–è¾¹ç•Œå’Œæ¦‚ç‡é¢„æµ‹
    è¿”å›ï¼šxx, yyï¼ˆç½‘æ ¼åæ ‡ï¼‰ã€grid_pointsï¼ˆå±•å¹³çš„ç½‘æ ¼ç‚¹ï¼‰
    """
    # è®¡ç®—ç½‘æ ¼èŒƒå›´ï¼ˆæ‰©å±•1å•ä½ï¼Œè¦†ç›–æ›´å¤šåŒºåŸŸï¼‰
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    
    # ç”Ÿæˆç½‘æ ¼
    xx, yy = np.meshgrid(
        np.arange(x_min, x_max, GRID_STEP),
        np.arange(y_min, y_max, GRID_STEP)
    )
    grid_points = np.c_[xx.ravel(), yy.ravel()]
    
    print(f"\nâœ… ç½‘æ ¼ç”Ÿæˆå®Œæˆï¼š")
    print(f"  - ç½‘æ ¼å°ºå¯¸ï¼š{xx.shape[0]}Ã—{xx.shape[1]}")
    print(f"  - é¢„æµ‹ç‚¹æ€»æ•°ï¼š{grid_points.shape[0]}")
    
    return xx, yy, grid_points

def predict_grid_results(model: LogisticRegression, grid_points: np.ndarray, xx: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    """
    é¢„æµ‹ç½‘æ ¼ç‚¹çš„ç±»åˆ«å’Œæ¦‚ç‡
    è¿”å›ï¼šé¢„æµ‹æ ‡ç­¾çŸ©é˜µã€ç±»åˆ«æ¦‚ç‡çŸ©é˜µ
    """
    try:
        # é¢„æµ‹ç±»åˆ«ï¼ˆå†³ç­–è¾¹ç•Œï¼‰
        pred_labels = model.predict(grid_points).reshape(xx.shape)
        
        # é¢„æµ‹æ¦‚ç‡ï¼ˆæ¯ä¸ªç±»åˆ«ï¼‰
        class_probs = model.predict_proba(grid_points)
        # é‡å¡‘ä¸º (height, width, classes)
        class_probs = class_probs.reshape(xx.shape[0], xx.shape[1], -1)
        
        # æ¦‚ç‡ç»´åº¦æ ¡éªŒ
        if class_probs.shape[-1] != len(CLASS_COLORS):
            raise ValueError(f"âŒ æ¦‚ç‡ç»´åº¦é”™è¯¯ï¼šæœŸæœ›{len(CLASS_COLORS)}ç±»ï¼Œå®é™…{class_probs.shape[-1]}ç±»")
        
        print(f"âœ… ç½‘æ ¼é¢„æµ‹å®Œæˆï¼š")
        print(f"  - é¢„æµ‹ç±»åˆ«èŒƒå›´ï¼š[{pred_labels.min()}, {pred_labels.max()}]")
        print(f"  - æ¦‚ç‡èŒƒå›´ï¼š[{class_probs.min():.3f}, {class_probs.max():.3f}]")
        
        return pred_labels, class_probs
    except NotFittedError:
        raise RuntimeError("âŒ æ¨¡å‹æœªè®­ç»ƒï¼Œæ— æ³•é¢„æµ‹")
    except Exception as e:
        raise RuntimeError(f"âŒ ç½‘æ ¼é¢„æµ‹å¤±è´¥ï¼š{str(e)}")

def plot_classifier_results(X: np.ndarray, y: np.ndarray, xx: np.ndarray, yy: np.ndarray,
                           pred_labels: np.ndarray, class_probs: np.ndarray):
    """
    ç»˜åˆ¶1Ã—4å­å›¾ï¼šæ•´ä½“å†³ç­–è¾¹ç•Œ + 3ä¸ªç±»åˆ«çš„æ¦‚ç‡å›¾
    """
    # åˆ›å»ºç”»å¸ƒï¼ˆ1è¡Œ4åˆ—ï¼‰
    fig, axs = plt.subplots(1, 4, figsize=FIG_SIZE, dpi=FIG_DPI)
    
    # ====================== å­å›¾1ï¼šæ•´ä½“å†³ç­–è¾¹ç•Œ ======================
    ax0 = axs[0]
    # ç»˜åˆ¶å†³ç­–åŒºåŸŸ
    ax0.imshow(
        pred_labels,
        extent=(xx.min(), xx.max(), yy.min(), yy.max()),
        origin='lower',
        cmap=mcolors.ListedColormap(CLASS_COLORS),
        alpha=0.6
    )
    # ç»˜åˆ¶æ•°æ®ç‚¹
    ax0.scatter(
        X[:, 0], X[:, 1],
        c=y, edgecolors='k', marker='o', s=50,
        cmap=mcolors.ListedColormap(CLASS_COLORS),
        alpha=1
    )
    # è®¾ç½®æ ·å¼
    ax0.set_title('Overall Decision Boundaries', fontsize=TITLE_FONT_SIZE)
    ax0.set_xlabel(FEATURE_NAMES[0], fontsize=LABEL_FONT_SIZE)
    ax0.set_ylabel(FEATURE_NAMES[1], fontsize=LABEL_FONT_SIZE)
    ax0.grid(alpha=0.3)
    
    # ====================== å­å›¾2-4ï¼šæ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡å›¾ ======================
    for i in range(len(CLASS_COLORS)):
        ax = axs[i+1]
        class_prob = class_probs[:, :, i]
        
        # åˆ›å»ºä¸“å±æ¸å˜è‰²æ˜ å°„ï¼ˆç™½è‰²â†’ç±»åˆ«è‰²ï¼‰
        cmap = mcolors.LinearSegmentedColormap.from_list(
            f'class_{i}_cmap', ['white', CLASS_COLORS[i]], N=256
        )
        
        # ç»˜åˆ¶æ¦‚ç‡å¡«å……å›¾
        contour = ax.contourf(xx, yy, class_prob, alpha=0.7, cmap=cmap, levels=20)
        
        # ç»˜åˆ¶æ•°æ®ç‚¹
        ax.scatter(
            X[:, 0], X[:, 1],
            c=y, edgecolors='k', marker='o', s=50,
            cmap=mcolors.ListedColormap(CLASS_COLORS),
            alpha=1
        )
        
        # æ·»åŠ é¢œè‰²æ¡ï¼ˆå¸¦æ ‡ç­¾ï¼‰
        cbar = fig.colorbar(contour, ax=ax)
        cbar.set_label(f'Probability (Class {i})', fontsize=LABEL_FONT_SIZE-1)
        
        # è®¾ç½®æ ·å¼
        ax.set_title(f'Class {i} Probability', fontsize=TITLE_FONT_SIZE)
        ax.set_xlabel(FEATURE_NAMES[0], fontsize=LABEL_FONT_SIZE)
        ax.set_ylabel(FEATURE_NAMES[1], fontsize=LABEL_FONT_SIZE)
        ax.grid(alpha=0.3)
    
    # è°ƒæ•´å¸ƒå±€å¹¶ä¿å­˜
    plt.tight_layout()
    plt.savefig(SAVE_PATH, dpi=FIG_DPI, bbox_inches='tight')
    print(f"\nâœ… å¯è§†åŒ–å›¾ç‰‡å·²ä¿å­˜è‡³ï¼š{SAVE_PATH}")
    
    # é‡Šæ”¾ç”»å¸ƒèµ„æº
    plt.close(fig)

def main():
    """ä¸»å‡½æ•°ï¼šä¸²è”æ‰€æœ‰æµç¨‹"""
    try:
        print("="*60)
        print("ğŸš€ å¼€å§‹æ‰§è¡Œé¸¢å°¾èŠ±åˆ†ç±»å†³ç­–è¾¹ç•Œå¯è§†åŒ–ä»»åŠ¡")
        print("="*60)
        
        # 1. åŠ è½½æ•°æ®ï¼ˆé€‰æ‹©åä¸¤ä¸ªç‰¹å¾ï¼‰
        X, y, target_names = load_iris_data()
        
        # 2. è®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹
        model, test_acc = train_logistic_regression(X, y)
        
        # 3. ç”Ÿæˆé¢„æµ‹ç½‘æ ¼
        xx, yy, grid_points = generate_grid(X)
        
        # 4. é¢„æµ‹ç½‘æ ¼ç‚¹çš„ç±»åˆ«å’Œæ¦‚ç‡
        pred_labels, class_probs = predict_grid_results(model, grid_points, xx)
        
        # 5. ç»˜åˆ¶å¹¶ä¿å­˜å¯è§†åŒ–ç»“æœ
        plot_classifier_results(X, y, xx, yy, pred_labels, class_probs)
        
        print("\nğŸ‰ ä»»åŠ¡å®Œæˆï¼")
        print(f"ğŸ“‹ æ¨¡å‹æµ‹è¯•é›†å‡†ç¡®ç‡ï¼š{test_acc:.3f} | å¯è§†åŒ–åŒ…å«ï¼šå†³ç­–è¾¹ç•Œ + 3ä¸ªç±»åˆ«æ¦‚ç‡å›¾")
        print("="*60)
        
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå¤±è´¥ï¼š{str(e)}")
        raise  # æŠ›å‡ºå¼‚å¸¸ä¾¿äºè°ƒè¯•

if __name__ == "__main__":
    main()